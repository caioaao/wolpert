{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scked generalization applied to a regression problem\n",
    "\n",
    "This example shows how stacked generalization can be used to combine several\n",
    "regressors into a single stacked one that performs better than the best\n",
    "regressor.\n",
    "\n",
    "The example uses the k-fold aproach to blending regressors on the inner layers.\n",
    "\n",
    "We use Boston's house pricing dataset to compare the mean squared error between\n",
    "three regressors (SVM, Lasso and Ridge regressions) and the combination of\n",
    "their outputs with a single linear regression. The following result is\n",
    "achieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "# import base regressors\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# stacking api\n",
    "from wolpert.pipeline import make_stack_layer\n",
    "from wolpert.pipeline import StackingPipeline\n",
    "\n",
    "# dataset\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "RANDOM_SEED = 89555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define and train the base regressors (the ones that will stay on the first layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso = LassoCV(random_state=RANDOM_SEED)\n",
    "ridge = RidgeCV()\n",
    "svr = SVR(C=1e3, gamma=1e-4, kernel='rbf')\n",
    "\n",
    "base_regressors = [(\"Lasso Regressor\", lasso),\n",
    "                   (\"Ridge Regressor\", ridge),\n",
    "                   (\"SVR\", svr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Lasso Regressor: 22.913 (train time: 0.045 seconds)\n",
      "MSE for Ridge Regressor: 21.699 (train time: 0.001 seconds)\n",
      "MSE for SVR: 21.227 (train time: 0.074 seconds)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_log_model(name, model):\n",
    "    t0_train = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time() - t0_train\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = mean_squared_error(y_test, y_pred)\n",
    "    print(\"MSE for %s: %.3f (train time: %.3f seconds)\"\n",
    "          % (name, score, train_time))\n",
    "\n",
    "    return train_time, score\n",
    "\n",
    "\n",
    "train_times = []\n",
    "scores = []\n",
    "labels = [name for name, _ in base_regressors]\n",
    "\n",
    "for i, (name, regressor) in enumerate(base_regressors):\n",
    "    train_time, score = evaluate_and_log_model(name, regressor)\n",
    "    train_times.append(train_time)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're really close to each other, and SVR is the winning one. Now let's build our stacked ensemble. On the first layer we'll use the three estimators we already have and, for the final estimator, we'll use a simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Stacked ensemble: 18.149 (train time: 0.268 seconds)\n"
     ]
    }
   ],
   "source": [
    "layer0 = make_stack_layer(lasso, ridge, svr)\n",
    "final_estimator = LinearRegression()\n",
    "\n",
    "stacked_reg = StackingPipeline([('layer-0', layer0),\n",
    "                                ('final', final_estimator)])\n",
    "\n",
    "train_time, score = evaluate_and_log_model('Stacked ensemble', stacked_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the stacked ensemble is better than the best of the estimators in the first layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
